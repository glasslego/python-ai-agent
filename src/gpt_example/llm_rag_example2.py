import os
from typing import List

from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

# API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


class AdvancedRAG:
    """OpenAI Embeddingì„ ì‚¬ìš©í•œ ê³ ê¸‰ RAG"""

    def __init__(self):
        self.documents = []
        self.embeddings = []

    def get_embedding(self, text: str) -> List[float]:
        """OpenAI Embedding APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            # OpenAI Embeddings API í˜¸ì¶œ
            # text-embedding-ada-002: OpenAIì˜ ìµœì‹  ì„ë² ë”© ëª¨ë¸
            response = client.embeddings.create(
                model="text-embedding-ada-002",  # ì„ë² ë”© ëª¨ë¸ ì§€ì •
                input=text,  # ë³€í™˜í•  í…ìŠ¤íŠ¸ ì…ë ¥
            )
            embedding_vector = response.data[0].embedding

            # ì„ë² ë”© ë²¡í„° ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            print(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ - ì°¨ì›: {len(embedding_vector)}")
            print(f"í…ìŠ¤íŠ¸: '{text[:50]}...' (ì²˜ìŒ 50ì)")
            print(
                f"ë²¡í„° ì˜ˆì‹œ: [{embedding_vector[0]:.6f}, {embedding_vector[1]:.6f}, ...]"
            )

            return embedding_vector
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return []

    def add_documents(self, documents: List[str]):
        """ë¬¸ì„œ ì¶”ê°€ ë° ì„ë² ë”© ìƒì„±"""
        self.documents = documents
        print("ğŸ”„ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")

        self.embeddings = []
        for doc in documents:
            embedding = self.get_embedding(doc)
            if embedding:
                self.embeddings.append(embedding)

        print(f"âœ… {len(self.embeddings)}ê°œ ë¬¸ì„œì˜ ì„ë² ë”©ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        dot_product = sum(x * y for x, y in zip(a, b))
        magnitude_a = sum(x * x for x in a) ** 0.5
        magnitude_b = sum(x * x for x in b) ** 0.5

        if magnitude_a == 0 or magnitude_b == 0:
            return 0

        return dot_product / (magnitude_a * magnitude_b)

    def retrieve_relevant_documents(self, query: str, top_k: int = 2) -> List[str]:
        """
        ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰ (OpenAI Embedding ì‚¬ìš©)

        Args:
            query (str): ê²€ìƒ‰í•  ì§ˆë¬¸
            top_k (int): ë°˜í™˜í•  ìƒìœ„ ë¬¸ì„œ ê°œìˆ˜

        Returns:
            List[str]: ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ (ìœ ì‚¬ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬)
        """
        if not self.documents or not self.embeddings:
            print("âš ï¸  ì €ì¥ëœ ë¬¸ì„œë‚˜ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        print(f"ğŸ” ì§ˆë¬¸ ì„ë² ë”© ìƒì„± ì¤‘: '{query}'")

        # 1. ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        query_embedding = self.get_embedding(query)
        if not query_embedding:
            print("âŒ ì§ˆë¬¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
            return []

        print("ğŸ“Š ë¬¸ì„œë“¤ê³¼ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")

        # 2. ëª¨ë“  ë¬¸ì„œì™€ ì§ˆë¬¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            similarity = self.cosine_similarity(query_embedding, doc_embedding)
            similarities.append(similarity)
            print(f"   ë¬¸ì„œ {i + 1}: ìœ ì‚¬ë„ = {similarity:.4f}")

        # 3. ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ kê°œ ë¬¸ì„œ ì„ íƒ
        # enumerateë¡œ ì¸ë±ìŠ¤ì™€ ìœ ì‚¬ë„ë¥¼ í•¨ê»˜ ì •ë ¬
        indexed_similarities = list(enumerate(similarities))
        # ìœ ì‚¬ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ kê°œ ì„ íƒ
        top_indices = sorted(
            indexed_similarities,
            key=lambda x: x[1],  # ìœ ì‚¬ë„(ë‘ ë²ˆì§¸ ìš”ì†Œ)ë¡œ ì •ë ¬
            reverse=True,  # ë‚´ë¦¼ì°¨ìˆœ
        )[:top_k]

        print(f"ğŸ¯ ìƒìœ„ {top_k}ê°œ ë¬¸ì„œ ì„ íƒ:")

        # 4. ì„ê³„ê°’ ì ìš©í•˜ì—¬ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë§Œ ì„ íƒ
        relevant_docs = []
        similarity_threshold = 0.7  # ìœ ì‚¬ë„ ì„ê³„ê°’ (70% ì´ìƒ)

        for idx, similarity in top_indices:
            print(
                f"   ìˆœìœ„ {len(relevant_docs) + 1}: ë¬¸ì„œ {idx + 1} (ìœ ì‚¬ë„: {similarity:.4f})"
            )

            if similarity > similarity_threshold:
                relevant_docs.append(self.documents[idx])
                print("     âœ… ì„ê³„ê°’ í†µê³¼ - ì„ íƒë¨")
            else:
                print(
                    f"     âŒ ì„ê³„ê°’ ë¯¸ë‹¬ ({similarity:.4f} <= {similarity_threshold}) - ì œì™¸"
                )

        if not relevant_docs:
            print(f"âš ï¸  ì„ê³„ê°’ {similarity_threshold} ì´ìƒì¸ ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        return relevant_docs


def advanced_rag_example():
    """ê³ ê¸‰ RAG ì˜ˆì‹œ"""
    print("ê³ ê¸‰ RAG (OpenAI Embedding ì‚¬ìš©) ì˜ˆì‹œ")

    advanced_rag = AdvancedRAG()

    # ê¸°ìˆ  ê´€ë ¨ ë¬¸ì„œë“¤
    tech_documents = [
        "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì— ì˜í•´ ê°œë°œëœ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.",
        "ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ, ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "DockerëŠ” ì»¨í…Œì´ë„ˆ ê¸°ë°˜ì˜ ê°€ìƒí™” í”Œë«í¼ìœ¼ë¡œ, ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.",
        "ReactëŠ” í˜ì´ìŠ¤ë¶ì—ì„œ ê°œë°œí•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•ì„ ìœ„í•œ JavaScript ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
    ]

    advanced_rag.add_documents(tech_documents)

    tech_questions = [
        "Pythonì˜ íŠ¹ì§•ì´ ë­ì•¼?",
        "ë¨¸ì‹ ëŸ¬ë‹ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜",
        "Dockerì˜ ì¥ì ì€?",
        "Reactë¥¼ ì™œ ì‚¬ìš©í•˜ë‚˜?",
    ]

    for question in tech_questions:
        print(f"\nğŸ” ì§ˆë¬¸: {question}")
        relevant_docs = advanced_rag.retrieve_relevant_documents(question)
        print(f"ğŸ“„ ê´€ë ¨ ë¬¸ì„œ: {relevant_docs}")


if __name__ == "__main__":
    advanced_rag_example()
