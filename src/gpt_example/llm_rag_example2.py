import os
from typing import List

from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

# API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


class AdvancedRAG:
    """OpenAI Embeddingì„ ì‚¬ìš©í•œ ê³ ê¸‰ RAG"""

    def __init__(self):
        self.documents = []
        self.embeddings = []

    def get_embedding(self, text: str) -> List[float]:
        """OpenAI Embedding APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            response = client.embeddings.create(
                model="text-embedding-ada-002", input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return []

    def add_documents(self, documents: List[str]):
        """ë¬¸ì„œ ì¶”ê°€ ë° ì„ë² ë”© ìƒì„±"""
        self.documents = documents
        print("ğŸ”„ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")

        self.embeddings = []
        for doc in documents:
            embedding = self.get_embedding(doc)
            if embedding:
                self.embeddings.append(embedding)

        print(f"âœ… {len(self.embeddings)}ê°œ ë¬¸ì„œì˜ ì„ë² ë”©ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        dot_product = sum(x * y for x, y in zip(a, b))
        magnitude_a = sum(x * x for x in a) ** 0.5
        magnitude_b = sum(x * x for x in b) ** 0.5

        if magnitude_a == 0 or magnitude_b == 0:
            return 0

        return dot_product / (magnitude_a * magnitude_b)

    def retrieve_relevant_documents(self, query: str, top_k: int = 2) -> List[str]:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰ (OpenAI Embedding ì‚¬ìš©)"""
        if not self.documents or not self.embeddings:
            return []

        query_embedding = self.get_embedding(query)
        if not query_embedding:
            return []

        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for doc_embedding in self.embeddings:
            similarity = self.cosine_similarity(query_embedding, doc_embedding)
            similarities.append(similarity)

        # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ ì„ íƒ
        top_indices = sorted(
            range(len(similarities)), key=lambda i: similarities[i], reverse=True
        )[:top_k]

        relevant_docs = [
            self.documents[i] for i in top_indices if similarities[i] > 0.7
        ]  # ì„ê³„ê°’ ì„¤ì •

        return relevant_docs


def advanced_rag_example():
    """ê³ ê¸‰ RAG ì˜ˆì‹œ"""
    print("ê³ ê¸‰ RAG (OpenAI Embedding ì‚¬ìš©) ì˜ˆì‹œ")

    advanced_rag = AdvancedRAG()

    # ê¸°ìˆ  ê´€ë ¨ ë¬¸ì„œë“¤
    tech_documents = [
        "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì— ì˜í•´ ê°œë°œëœ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.",
        "ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ, ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "DockerëŠ” ì»¨í…Œì´ë„ˆ ê¸°ë°˜ì˜ ê°€ìƒí™” í”Œë«í¼ìœ¼ë¡œ, ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë°°í¬í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.",
        "ReactëŠ” í˜ì´ìŠ¤ë¶ì—ì„œ ê°œë°œí•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•ì„ ìœ„í•œ JavaScript ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
    ]

    advanced_rag.add_documents(tech_documents)

    tech_questions = [
        "Pythonì˜ íŠ¹ì§•ì´ ë­ì•¼?",
        "ë¨¸ì‹ ëŸ¬ë‹ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜",
        "Dockerì˜ ì¥ì ì€?",
        "Reactë¥¼ ì™œ ì‚¬ìš©í•˜ë‚˜?",
    ]

    for question in tech_questions:
        print(f"\nğŸ” ì§ˆë¬¸: {question}")
        relevant_docs = advanced_rag.retrieve_relevant_documents(question)
        print(f"ğŸ“„ ê´€ë ¨ ë¬¸ì„œ: {relevant_docs}")


if __name__ == "__main__":
    advanced_rag_example()
