# flake8: noqa: E501

import warnings

import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import squareform
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = [
    "DejaVu Sans",
    "AppleGothic",
    "Malgun Gothic",
    "gulim",
    "Arial Unicode MS",
]
plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# í°íŠ¸ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings(
    "ignore", category=UserWarning, module="matplotlib.font_manager"
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = "DejaVu Sans"
plt.rcParams["axes.unicode_minus"] = False


class SimilarityAnalyzer:
    """ë¬¸ì„œ ìœ ì‚¬ë„ ë¶„ì„"""

    def __init__(self, tfidf_matrix):
        self.tfidf_matrix = tfidf_matrix
        self.similarity_matrix = None

    def compute_similarity_matrix(self):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°"""
        self.similarity_matrix = cosine_similarity(self.tfidf_matrix)

        print(f"âœ… ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° ì™„ë£Œ ({self.similarity_matrix.shape})")

        return self.similarity_matrix

    def find_similar_articles(self, article_index, df, n_similar=3):
        """íŠ¹ì • ê¸°ì‚¬ì™€ ìœ ì‚¬í•œ ê¸°ì‚¬ë“¤ ì°¾ê¸°"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        # ìê¸° ìì‹ ì„ ì œì™¸í•œ ìœ ì‚¬ë„ ì ìˆ˜
        similarities = self.similarity_matrix[article_index].copy()
        similarities[article_index] = -1  # ìê¸° ìì‹  ì œì™¸

        # ìƒìœ„ ìœ ì‚¬ ê¸°ì‚¬ ì¸ë±ìŠ¤
        similar_indices = similarities.argsort()[-n_similar:][::-1]

        print(f"\nğŸ”— '{df.iloc[article_index]['Title'][:40]}...'ì™€ ìœ ì‚¬í•œ ê¸°ì‚¬ë“¤:")

        similar_articles = []
        for i, idx in enumerate(similar_indices, 1):
            title = df.iloc[idx]["Title"]
            similarity_score = similarities[idx]
            print(f"   {i}. {title[:50]}... (ìœ ì‚¬ë„: {similarity_score:.3f})")

            similar_articles.append(
                {"index": idx, "title": title, "similarity": similarity_score}
            )

        return similar_articles

    def analyze_overall_similarity(self, df):
        """ì „ì²´ ìœ ì‚¬ë„ ë¶„ì„"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        # ëŒ€ê°ì„  ì œì™¸ (ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„ ì œì™¸)
        mask = np.triu(np.ones_like(self.similarity_matrix, dtype=bool), k=1)
        similarities = self.similarity_matrix[mask]

        print("\nğŸ“Š ì „ì²´ ìœ ì‚¬ë„ í†µê³„:")
        print(f"   í‰ê·  ìœ ì‚¬ë„: {similarities.mean():.3f}")
        print(f"   ìµœëŒ€ ìœ ì‚¬ë„: {similarities.max():.3f}")
        print(f"   ìµœì†Œ ìœ ì‚¬ë„: {similarities.min():.3f}")

        # ê°€ì¥ ìœ ì‚¬í•œ ê¸°ì‚¬ ìŒ ì°¾ê¸°
        max_sim_value = similarities.max()
        max_indices = np.where(self.similarity_matrix == max_sim_value)
        i, j = max_indices[0][0], max_indices[1][0]

        print("\nğŸ¯ ê°€ì¥ ìœ ì‚¬í•œ ê¸°ì‚¬ ìŒ:")
        print(f"   1. {df.iloc[i]['Title'][:40]}...")
        print(f"   2. {df.iloc[j]['Title'][:40]}...")
        print(f"   ìœ ì‚¬ë„: {max_sim_value:.3f}")

        return {
            "mean_similarity": similarities.mean(),
            "max_similarity": similarities.max(),
            "min_similarity": similarities.min(),
            "most_similar_pair": (i, j, max_sim_value),
        }

    def visualize_similarity_matrix(self, df, top_n=None):
        """ìœ ì‚¬ë„ í–‰ë ¬ ì‹œê°í™”"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        print("\nğŸ“Š ìœ ì‚¬ë„ í–‰ë ¬ ì‹œê°í™” ìƒì„± ì¤‘...")

        # ìƒìœ„ Nê°œ ë¬¸ì„œë§Œ ì‹œê°í™” (ê°€ë…ì„±ì„ ìœ„í•´)
        if top_n is None:
            top_n = min(20, len(df))

        matrix_subset = self.similarity_matrix[:top_n, :top_n]
        titles_subset = [
            title[:20] + "..." if len(title) > 20 else title
            for title in df["Title"].head(top_n)
        ]

        plt.figure(figsize=(12, 10))

        # íˆíŠ¸ë§µ ìƒì„±
        mask = np.triu(np.ones_like(matrix_subset, dtype=bool))  # ìƒì‚¼ê° ë§ˆìŠ¤í¬

        sns.heatmap(
            matrix_subset,
            mask=mask,
            xticklabels=titles_subset,
            yticklabels=titles_subset,
            annot=True if top_n <= 10 else False,
            fmt=".2f",
            cmap="coolwarm",
            center=0.5,
            square=True,
            cbar_kws={"label": "Cosine Similarity"},
        )

        plt.title(
            f"Document Similarity Matrix (Top {top_n})", fontsize=16, fontweight="bold"
        )
        plt.xticks(rotation=45, ha="right")
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.savefig("similarity_matrix_heatmap.png", dpi=300, bbox_inches="tight")
        plt.show()

        print("   ğŸ“ íˆíŠ¸ë§µì´ 'similarity_matrix_heatmap.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def create_similarity_distribution(self):
        """ìœ ì‚¬ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        print("\nğŸ“ˆ ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„ ì¤‘...")

        # ëŒ€ê°ì„  ì œì™¸í•œ ìœ ì‚¬ë„ ê°’ë“¤
        mask = np.triu(np.ones_like(self.similarity_matrix, dtype=bool), k=1)
        similarities = self.similarity_matrix[mask]

        plt.figure(figsize=(15, 5))

        # 1. íˆìŠ¤í† ê·¸ë¨
        plt.subplot(1, 3, 1)
        plt.hist(similarities, bins=30, alpha=0.7, color="skyblue", edgecolor="black")
        plt.axvline(
            similarities.mean(),
            color="red",
            linestyle="--",
            label=f"Mean: {similarities.mean():.3f}",
        )
        plt.title("Similarity Distribution", fontweight="bold")
        plt.xlabel("Cosine Similarity")
        plt.ylabel("Frequency")
        plt.legend()
        plt.grid(True, alpha=0.3)

        # 2. ë°•ìŠ¤í”Œë¡¯
        plt.subplot(1, 3, 2)
        plt.boxplot(similarities)
        plt.title("Similarity Box Plot", fontweight="bold")
        plt.ylabel("Cosine Similarity")
        plt.grid(True, alpha=0.3)

        # 3. ëˆ„ì  ë¶„í¬
        plt.subplot(1, 3, 3)
        sorted_sim = np.sort(similarities)
        cumulative = np.arange(1, len(sorted_sim) + 1) / len(sorted_sim)
        plt.plot(sorted_sim, cumulative, linewidth=2)
        plt.title("Cumulative Distribution", fontweight="bold")
        plt.xlabel("Cosine Similarity")
        plt.ylabel("Cumulative Probability")
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(
            "similarity_distribution_analysis.png", dpi=300, bbox_inches="tight"
        )
        plt.show()

        print(
            "   ğŸ“ ë¶„í¬ ë¶„ì„ì´ 'similarity_distribution_analysis.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        )

    def create_similarity_network(self, df, threshold=0.3, top_n=15):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        print(f"\nğŸ•¸ï¸  ìœ ì‚¬ë„ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì¤‘... (ì„ê³„ê°’: {threshold})")

        # ìƒìœ„ Nê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
        matrix_subset = self.similarity_matrix[:top_n, :top_n]
        titles_subset = df["Title"].head(top_n).tolist()

        # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
        G = nx.Graph()

        # ë…¸ë“œ ì¶”ê°€
        for i, title in enumerate(titles_subset):
            G.add_node(i, title=title[:30] + "..." if len(title) > 30 else title)

        # ì—£ì§€ ì¶”ê°€ (ì„ê³„ê°’ ì´ìƒì˜ ìœ ì‚¬ë„)
        for i in range(len(matrix_subset)):
            for j in range(i + 1, len(matrix_subset)):
                similarity = matrix_subset[i, j]
                if similarity > threshold:
                    G.add_edge(i, j, weight=similarity)

        # ê·¸ë˜í”„ ì‹œê°í™”
        plt.figure(figsize=(14, 10))

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        if len(G.edges()) > 0:
            pos = nx.spring_layout(G, k=2, iterations=50)
        else:
            pos = nx.circular_layout(G)

        # ë…¸ë“œ í¬ê¸° (ì—°ê²° ìˆ˜ì— ë¹„ë¡€)
        node_sizes = [300 + G.degree(node) * 100 for node in G.nodes()]

        # ì—£ì§€ ë‘ê»˜ (ìœ ì‚¬ë„ì— ë¹„ë¡€)
        edge_weights = [G[u][v]["weight"] * 5 for u, v in G.edges()]

        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        nx.draw_networkx_nodes(
            G, pos, node_size=node_sizes, node_color="lightblue", alpha=0.7
        )

        if len(G.edges()) > 0:
            nx.draw_networkx_edges(
                G, pos, width=edge_weights, alpha=0.6, edge_color="gray"
            )

        # ë…¸ë“œ ë¼ë²¨
        labels = {node: data["title"] for node, data in G.nodes(data=True)}
        nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight="bold")

        plt.title(
            f"Document Similarity Network (Threshold: {threshold})",
            fontsize=16,
            fontweight="bold",
        )
        plt.axis("off")
        plt.tight_layout()
        plt.savefig("similarity_network.png", dpi=300, bbox_inches="tight")
        plt.show()

        print("   ğŸ“ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ê°€ 'similarity_network.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"   ğŸ”— ì—°ê²°ëœ ì—£ì§€ ìˆ˜: {len(G.edges())}")

    def create_dendrogram(self, df, top_n=20):
        """ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ ë´ë“œë¡œê·¸ë¨"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        print("\nğŸŒ³ ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ ë´ë“œë¡œê·¸ë¨ ìƒì„± ì¤‘...")

        # ìƒìœ„ Nê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
        matrix_subset = self.similarity_matrix[:top_n, :top_n]
        titles_subset = [
            title[:25] + "..." if len(title) > 25 else title
            for title in df["Title"].head(top_n)
        ]

        # ê±°ë¦¬ í–‰ë ¬ë¡œ ë³€í™˜ (1 - ìœ ì‚¬ë„)
        distance_matrix = 1 - matrix_subset

        # ëŒ€ê°ì„ ì„ 0ìœ¼ë¡œ ì„¤ì • (ìê¸° ìì‹ ê³¼ì˜ ê±°ë¦¬)
        np.fill_diagonal(distance_matrix, 0)

        # ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§
        condensed_distances = squareform(distance_matrix)
        linkage_matrix = linkage(condensed_distances, method="ward")

        # ë´ë“œë¡œê·¸ë¨ ìƒì„±
        plt.figure(figsize=(15, 8))

        dendrogram(
            linkage_matrix,
            labels=titles_subset,
            orientation="top",
            distance_sort="descending",
            show_leaf_counts=True,
        )

        plt.title("Hierarchical Clustering Dendrogram", fontsize=16, fontweight="bold")
        plt.xlabel("Documents")
        plt.ylabel("Distance")
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        plt.savefig("similarity_dendrogram.png", dpi=300, bbox_inches="tight")
        plt.show()

        print("   ğŸ“ ë´ë“œë¡œê·¸ë¨ì´ 'similarity_dendrogram.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def find_outliers(self, df, threshold=0.1):
        """ìœ ì‚¬ë„ê°€ ë‚®ì€ ì´ìƒì¹˜ ë¬¸ì„œ ì°¾ê¸°"""
        if self.similarity_matrix is None:
            self.compute_similarity_matrix()

        print(f"\nğŸ¯ ì´ìƒì¹˜ ë¬¸ì„œ íƒì§€ ì¤‘... (ì„ê³„ê°’: {threshold})")

        # ê° ë¬¸ì„œì˜ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚° (ìê¸° ìì‹  ì œì™¸)
        avg_similarities = []
        for i in range(len(self.similarity_matrix)):
            similarities = self.similarity_matrix[i].copy()
            similarities[i] = 0  # ìê¸° ìì‹  ì œì™¸
            avg_sim = similarities.mean()
            avg_similarities.append(avg_sim)

        # ì„ê³„ê°’ ì´í•˜ì¸ ë¬¸ì„œë“¤ ì°¾ê¸°
        outliers = []
        for i, avg_sim in enumerate(avg_similarities):
            if avg_sim < threshold:
                outliers.append(
                    {
                        "index": i,
                        "title": df.iloc[i]["Title"],
                        "avg_similarity": avg_sim,
                    }
                )

        if outliers:
            print(f"   ğŸ“‹ ë°œê²¬ëœ ì´ìƒì¹˜ ë¬¸ì„œ ({len(outliers)}ê°œ):")
            for outlier in outliers:
                print(
                    f"   â€¢ {outlier['title'][:50]}... (í‰ê·  ìœ ì‚¬ë„: {outlier['avg_similarity']:.3f})"
                )
        else:
            print("   âœ… ì„ê³„ê°’ ì´í•˜ì˜ ì´ìƒì¹˜ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        return outliers


def save_similarity_results(analyzer, df, similar_pairs, outliers):
    """ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    print("\nğŸ’¾ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")

    # 1. ìœ ì‚¬ë„ í–‰ë ¬ ì €ì¥
    similarity_df = pd.DataFrame(
        analyzer.similarity_matrix,
        columns=[f"Doc_{i}" for i in range(len(df))],
        index=[f"Doc_{i}" for i in range(len(df))],
    )
    similarity_df.to_csv("similarity_matrix.csv", encoding="utf-8-sig")
    print("   ğŸ“Š ìœ ì‚¬ë„ í–‰ë ¬: similarity_matrix.csv")

    # 2. ìœ ì‚¬í•œ ë¬¸ì„œ ìŒ ì €ì¥
    if similar_pairs:
        pairs_data = []
        for pair in similar_pairs:
            pairs_data.append(
                {
                    "doc1_index": pair["doc1_idx"],
                    "doc1_title": pair["doc1_title"],
                    "doc2_index": pair["doc2_idx"],
                    "doc2_title": pair["doc2_title"],
                    "similarity": pair["similarity"],
                }
            )

        pairs_df = pd.DataFrame(pairs_data)
        pairs_df.to_csv("similar_document_pairs.csv", index=False, encoding="utf-8-sig")
        print("   ğŸ”— ìœ ì‚¬ ë¬¸ì„œ ìŒ: similar_document_pairs.csv")

    # 3. ì´ìƒì¹˜ ë¬¸ì„œ ì €ì¥
    if outliers:
        outliers_df = pd.DataFrame(outliers)
        outliers_df.to_csv("outlier_documents.csv", index=False, encoding="utf-8-sig")
        print("   ğŸ¯ ì´ìƒì¹˜ ë¬¸ì„œ: outlier_documents.csv")

    # 4. ë¬¸ì„œë³„ í‰ê·  ìœ ì‚¬ë„ ì €ì¥
    avg_similarities = []
    for i in range(len(analyzer.similarity_matrix)):
        similarities = analyzer.similarity_matrix[i].copy()
        similarities[i] = 0  # ìê¸° ìì‹  ì œì™¸
        avg_sim = similarities.mean()
        avg_similarities.append(
            {"doc_index": i, "title": df.iloc[i]["Title"], "avg_similarity": avg_sim}
        )

    avg_sim_df = pd.DataFrame(avg_similarities)
    avg_sim_df = avg_sim_df.sort_values("avg_similarity", ascending=False)
    avg_sim_df.to_csv(
        "document_avg_similarities.csv", index=False, encoding="utf-8-sig"
    )
    print("   ğŸ“ˆ ë¬¸ì„œë³„ í‰ê·  ìœ ì‚¬ë„: document_avg_similarities.csv")


def find_top_similar_pairs(analyzer, df, top_k=5):
    """ìƒìœ„ ìœ ì‚¬ ë¬¸ì„œ ìŒ ì°¾ê¸°"""
    if analyzer.similarity_matrix is None:
        analyzer.compute_similarity_matrix()

    # ìƒì‚¼ê° í–‰ë ¬ì—ì„œ ìœ ì‚¬ë„ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
    mask = np.triu(np.ones_like(analyzer.similarity_matrix, dtype=bool), k=1)
    similarities = analyzer.similarity_matrix[mask]

    # ìƒìœ„ kê°œ ìœ ì‚¬ë„ ì¸ë±ìŠ¤ ì°¾ê¸°
    top_indices = similarities.argsort()[-top_k:][::-1]

    # 2D ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    mask_indices = np.where(mask)
    top_pairs = []

    for idx in top_indices:
        i, j = mask_indices[0][idx], mask_indices[1][idx]
        similarity = analyzer.similarity_matrix[i, j]

        top_pairs.append(
            {
                "doc1_idx": i,
                "doc1_title": df.iloc[i]["Title"],
                "doc2_idx": j,
                "doc2_title": df.iloc[j]["Title"],
                "similarity": similarity,
            }
        )

    print(f"\nğŸ† ìƒìœ„ {top_k}ê°œ ìœ ì‚¬ ë¬¸ì„œ ìŒ:")
    for idx, pair in enumerate(top_pairs, 1):
        print(f"   {idx}. ìœ ì‚¬ë„ {pair['similarity']:.3f}")
        print(f"      â€¢ {pair['doc1_title'][:40]}...")
        print(f"      â€¢ {pair['doc2_title'][:40]}...")

    return top_pairs


def main():
    print("ğŸ” ë¬¸ì„œ ìœ ì‚¬ë„ ë¶„ì„ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    print("=" * 50)

    # 1. ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv("it_news_articles_processed.csv")
    print(f"   âœ… news_data.csv íŒŒì¼ì—ì„œ {len(df)}ê°œ ê¸°ì‚¬ ë¡œë“œ")

    # ë°ì´í„° ê¸°ë³¸ ì •ë³´ ì¶œë ¥
    print("\nğŸ“‹ ë°ì´í„° ì •ë³´:")
    print(f"   â€¢ ì´ ê¸°ì‚¬ ìˆ˜: {len(df)}")

    # 2. TF-IDF ë²¡í„°í™”
    vectorizer = TfidfVectorizer(
        max_features=1000,
        stop_words="english",
        ngram_range=(1, 2),
        min_df=1,
        max_df=0.95,
    )

    tfidf_matrix = vectorizer.fit_transform(df["processed_content"])

    print("   âœ… TF-IDF ë²¡í„°í™” ì™„ë£Œ")
    print(f"   â€¢ íŠ¹ì„± ìˆ˜: {tfidf_matrix.shape[1]}")
    print(f"   â€¢ ë¬¸ì„œ ìˆ˜: {tfidf_matrix.shape[0]}")

    # 3. ìœ ì‚¬ë„ ë¶„ì„ê¸° ì´ˆê¸°í™”
    print("\nğŸ¯ ìœ ì‚¬ë„ ë¶„ì„ ì‹œì‘...")
    analyzer = SimilarityAnalyzer(tfidf_matrix)

    # 4. ì „ì²´ ìœ ì‚¬ë„ ë¶„ì„
    overall_stats = analyzer.analyze_overall_similarity(df)

    # 5. íŠ¹ì • ê¸°ì‚¬ì™€ ìœ ì‚¬í•œ ê¸°ì‚¬ ì°¾ê¸° (ì˜ˆì‹œ)
    if len(df) > 1:
        print("\nğŸ” íŠ¹ì • ê¸°ì‚¬ ìœ ì‚¬ë„ ë¶„ì„ ì˜ˆì‹œ:")
        sample_article_idx = 0
        similar_articles = analyzer.find_similar_articles(
            sample_article_idx, df, n_similar=3
        )
        print(similar_articles)

    # 6. ìƒìœ„ ìœ ì‚¬ ë¬¸ì„œ ìŒ ì°¾ê¸°
    top_pairs = find_top_similar_pairs(analyzer, df, top_k=5)

    # 7. ì´ìƒì¹˜ ë¬¸ì„œ íƒì§€
    outliers = analyzer.find_outliers(df, threshold=0.1)

    # 8. ì‹œê°í™” ìƒì„±
    if len(df) > 1:
        print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")

        # ìœ ì‚¬ë„ í–‰ë ¬ íˆíŠ¸ë§µ
        analyzer.visualize_similarity_matrix(df, top_n=min(15, len(df)))

        # ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„
        analyzer.create_similarity_distribution()

        # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ (ë¬¸ì„œê°€ ì¶©ë¶„í•œ ê²½ìš°)
        if len(df) >= 5:
            analyzer.create_similarity_network(
                df, threshold=0.2, top_n=min(12, len(df))
            )

        # ë´ë“œë¡œê·¸ë¨ (ë¬¸ì„œê°€ ì¶©ë¶„í•œ ê²½ìš°)
        if len(df) >= 3:
            analyzer.create_dendrogram(df, top_n=min(15, len(df)))
    else:
        print("\nâš ï¸  ë¬¸ì„œ ìˆ˜ê°€ ë¶€ì¡±í•˜ì—¬ ì‹œê°í™”ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")

    # 9. ê²°ê³¼ ì €ì¥
    save_similarity_results(analyzer, df, top_pairs, outliers)

    # 10. ê°œë³„ ë¬¸ì„œ ë¶„ì„ ë„êµ¬ (ì‚¬ìš©ì ì…ë ¥)
    print("\nğŸ”§ ê°œë³„ ë¬¸ì„œ ë¶„ì„ ë„êµ¬")
    print("-" * 25)
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
    print("1. 'similar <ìˆ«ì>' - íŠ¹ì • ì¸ë±ìŠ¤ ë¬¸ì„œì˜ ìœ ì‚¬ ë¬¸ì„œ ì°¾ê¸°")
    print("2. 'compare <ìˆ«ì1> <ìˆ«ì2>' - ë‘ ë¬¸ì„œ ì§ì ‘ ë¹„êµ")
    print("3. 'list' - ëª¨ë“  ë¬¸ì„œ ëª©ë¡ ë³´ê¸°")
    print("4. 'stats' - ì „ì²´ í†µê³„ ë‹¤ì‹œ ë³´ê¸°")
    print("5. 'quit' - ì¢…ë£Œ")

    while True:
        try:
            command = input("\nëª…ë ¹ì–´ ì…ë ¥ (ë˜ëŠ” 'quit'): ").strip().lower()

            if command == "quit":
                break
            elif command == "list":
                print("\nğŸ“‹ ë¬¸ì„œ ëª©ë¡:")
                for i, title in enumerate(df["Title"]):
                    print(f"   {i}: {title[:60]}...")
            elif command == "stats":
                print("\nğŸ“Š ì „ì²´ ìœ ì‚¬ë„ í†µê³„:")
                print(f"   í‰ê·  ìœ ì‚¬ë„: {overall_stats['mean_similarity']:.3f}")
                print(f"   ìµœëŒ€ ìœ ì‚¬ë„: {overall_stats['max_similarity']:.3f}")
                print(f"   ìµœì†Œ ìœ ì‚¬ë„: {overall_stats['min_similarity']:.3f}")
            elif command.startswith("similar "):
                try:
                    idx = int(command.split()[1])
                    if 0 <= idx < len(df):
                        analyzer.find_similar_articles(idx, df, n_similar=5)
                    else:
                        print(
                            f"   âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤. (0-{len(df) - 1} ë²”ìœ„)"
                        )
                except (ValueError, IndexError):
                    print("   âŒ ì˜¬ë°”ë¥¸ í˜•ì‹: 'similar <ìˆ«ì>'")
            elif command.startswith("compare "):
                try:
                    parts = command.split()
                    idx1, idx2 = int(parts[1]), int(parts[2])
                    if 0 <= idx1 < len(df) and 0 <= idx2 < len(df):
                        similarity = analyzer.similarity_matrix[idx1, idx2]
                        print("\nğŸ” ë¬¸ì„œ ë¹„êµ:")
                        print(f"   ë¬¸ì„œ {idx1}: {df.iloc[idx1]['Title'][:50]}...")
                        print(f"   ë¬¸ì„œ {idx2}: {df.iloc[idx2]['Title'][:50]}...")
                        print(f"   ìœ ì‚¬ë„: {similarity:.3f}")
                    else:
                        print(
                            f"   âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤. (0-{len(df) - 1} ë²”ìœ„)"
                        )
                except (ValueError, IndexError):
                    print("   âŒ ì˜¬ë°”ë¥¸ í˜•ì‹: 'compare <ìˆ«ì1> <ìˆ«ì2>'")
            else:
                print(
                    "   âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. 'list', 'similar <ìˆ«ì>', 'compare <ìˆ«ì1> <ìˆ«ì2>', 'stats', 'quit' ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
                )

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # 11. ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸
    print("\nğŸ“Š ìµœì¢… ë¶„ì„ ìš”ì•½")
    print("=" * 30)
    print(f"â€¢ ì´ ë¬¸ì„œ ìˆ˜: {len(df)}")
    print(f"â€¢ í‰ê·  ìœ ì‚¬ë„: {overall_stats['mean_similarity']:.3f}")
    print(f"â€¢ ìµœëŒ€ ìœ ì‚¬ë„: {overall_stats['max_similarity']:.3f}")
    print(f"â€¢ ìƒìœ„ ìœ ì‚¬ ìŒ ìˆ˜: {len(top_pairs)}")
    print(f"â€¢ ì´ìƒì¹˜ ë¬¸ì„œ ìˆ˜: {len(outliers)}")

    # ì¹´í…Œê³ ë¦¬ë³„ ìœ ì‚¬ë„ ë¶„ì„
    high_similarity_pairs = len([p for p in top_pairs if p["similarity"] > 0.5])
    medium_similarity_pairs = len(
        [p for p in top_pairs if 0.2 <= p["similarity"] <= 0.5]
    )
    low_similarity_pairs = len([p for p in top_pairs if p["similarity"] < 0.2])

    print("\nğŸ“ˆ ìœ ì‚¬ë„ ë¶„í¬:")
    print(f"  â€¢ ë†’ì€ ìœ ì‚¬ë„ (>0.5): {high_similarity_pairs}ìŒ")
    print(f"  â€¢ ì¤‘ê°„ ìœ ì‚¬ë„ (0.2-0.5): {medium_similarity_pairs}ìŒ")
    print(f"  â€¢ ë‚®ì€ ìœ ì‚¬ë„ (<0.2): {low_similarity_pairs}ìŒ")

    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print("  â€¢ similarity_matrix.csv - ì „ì²´ ìœ ì‚¬ë„ í–‰ë ¬")
    print("  â€¢ similar_document_pairs.csv - ìƒìœ„ ìœ ì‚¬ ë¬¸ì„œ ìŒ")
    print("  â€¢ document_avg_similarities.csv - ë¬¸ì„œë³„ í‰ê·  ìœ ì‚¬ë„")
    if outliers:
        print("  â€¢ outlier_documents.csv - ì´ìƒì¹˜ ë¬¸ì„œ ëª©ë¡")
    if len(df) > 1:
        print("  â€¢ similarity_matrix_heatmap.png - ìœ ì‚¬ë„ íˆíŠ¸ë§µ")
        print("  â€¢ similarity_distribution_analysis.png - ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„")
        if len(df) >= 5:
            print("  â€¢ similarity_network.png - ìœ ì‚¬ë„ ë„¤íŠ¸ì›Œí¬")
        if len(df) >= 3:
            print("  â€¢ similarity_dendrogram.png - ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§")

    print("\nğŸ‰ ë¬¸ì„œ ìœ ì‚¬ë„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    return analyzer, overall_stats, top_pairs, outliers


if __name__ == "__main__":
    results = main()
    analyzer, overall_stats, top_pairs, outliers = results
