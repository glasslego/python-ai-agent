from dotenv import load_dotenv
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    PromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ============================================================
# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# ============================================================


def prompt_template_basic():
    """
    ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš© ì˜ˆì œ
    """

    # í…œí”Œë¦¿ ìƒì„±
    template = """
    ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤.

    ì§ˆë¬¸: {question}

    {style} ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    """

    prompt = PromptTemplate(
        input_variables=["role", "question", "style"], template=template
    )

    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
    )

    # ë‹¤ì–‘í•œ ì¡°í•©ìœ¼ë¡œ ì‚¬ìš©
    examples = [
        {
            "role": "ê³¼í•™ ì„ ìƒë‹˜",
            "question": "ë¸”ë™í™€ì´ ë­ì•¼?",
            "style": "ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ”",
        },
        {
            "role": "ìš”ë¦¬ì‚¬",
            "question": "íŒŒìŠ¤íƒ€ ë§Œë“œëŠ” ë²•",
            "style": "ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ",
        },
        {"role": "ì‹œì¸", "question": "ë´„ì˜ ì•„ë¦„ë‹¤ì›€", "style": "ê°ì„±ì ì´ê³  ì€ìœ ì ì¸"},
    ]

    for example in examples:
        formatted = prompt.format(**example)
        response = llm.invoke(formatted)
        print(f"\n[{example['role']}ì˜ {example['style']} ë‹µë³€]")
        print(response.content[:200] + "...")

    return prompt


def prompt_template_chat():
    """
    ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì˜ˆì œ
    """

    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ í…œí”Œë¦¿
    system_template = "ë‹¹ì‹ ì€ {expertise} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ {tone} í†¤ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”."
    system_prompt = SystemMessagePromptTemplate.from_template(system_template)

    # ì‚¬ìš©ì ë©”ì‹œì§€ í…œí”Œë¦¿
    human_template = "{question}"
    human_prompt = HumanMessagePromptTemplate.from_template(human_template)

    # ì „ì²´ ëŒ€í™” í…œí”Œë¦¿
    chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])

    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
    )

    # ì‚¬ìš© ì˜ˆì‹œ
    messages = chat_prompt.format_messages(
        expertise="Python í”„ë¡œê·¸ë˜ë°",
        tone="ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ”",
        question="ì½”ë”©ì„ ì²˜ìŒ ì‹œì‘í•˜ëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?",
    )

    response = llm.invoke(messages)
    print("ëŒ€í™”í˜• í…œí”Œë¦¿ ì‘ë‹µ:")
    print(response.content)

    return chat_prompt


def prompt_template_few_shot():
    """
    Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì˜ˆì œ (ì˜ˆì‹œë¥¼ í¬í•¨í•œ í•™ìŠµ)
    """
    from langchain.prompts import FewShotPromptTemplate, PromptTemplate
    from langchain_openai import ChatOpenAI

    # ì˜ˆì‹œ ë°ì´í„°
    examples = [
        {"input": "happy", "output": "ğŸ˜Š"},
        {"input": "sad", "output": "ğŸ˜¢"},
        {"input": "angry", "output": "ğŸ˜ "},
        {"input": "love", "output": "â¤ï¸"},
    ]

    # ì˜ˆì‹œ í…œí”Œë¦¿
    example_template = """
    ì…ë ¥: {input}
    ì¶œë ¥: {output}
    """

    example_prompt = PromptTemplate(
        input_variables=["input", "output"], template=example_template
    )

    # Few-shot í”„ë¡¬í”„íŠ¸
    few_shot_prompt = FewShotPromptTemplate(
        examples=examples,
        example_prompt=example_prompt,
        prefix="ê°ì •ì„ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:",
        suffix="ì…ë ¥: {emotion}\nì¶œë ¥:",
        input_variables=["emotion"],
    )

    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0,
    )

    # í…ŒìŠ¤íŠ¸
    test_emotions = ["excited", "tired", "surprised"]

    for emotion in test_emotions:
        prompt = few_shot_prompt.format(emotion=emotion)
        response = llm.invoke(prompt)
        print(f"{emotion} â†’ {response.content}")

    return few_shot_prompt


if __name__ == "__main__":
    print("í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì˜ˆì œ ì‹¤í–‰")
    prompt_template_basic()
    prompt_template_chat()
    prompt_template_few_shot()
