{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai pypdf faiss-cpu python-dotenv tiktoken langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdcdef9bacceabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° API í‚¤ ì„¤ì •\n",
    "# ==============================================================================\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from google.colab import files\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.\n",
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜\n",
    "# ==============================================================================\n",
    "def process_text_to_vectorstore(text: str):\n",
    "    \"\"\"\n",
    "    ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ê³ , ì„ë² ë”©í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œ(FAISS)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        print(f\"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def summarize_with_langchain(documents, query: str):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ë¬¸ì„œì™€ ì¿¼ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ LangChainì„ ì´ìš©í•´ ë‹µë³€ì„ ìƒì„±í•˜ê³  ë¹„ìš©ì„ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    docs = documents.similarity_search(query)\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "    with get_openai_callback() as cost_tracker:\n",
    "        response_dict = chain.invoke({\"input_documents\": docs, \"question\": query})\n",
    "        print(\"\\n[ë¹„ìš© ì •ë³´]\")\n",
    "        print(cost_tracker)\n",
    "\n",
    "    return response_dict.get(\"output_text\", \"ìš”ì•½ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Colabì—ì„œ ì‹¤í–‰í•  ë©”ì¸ ë¡œì§\n",
    "# ==============================================================================\n",
    "def run_in_colab():\n",
    "    \"\"\"\n",
    "    Google Colab í™˜ê²½ì—ì„œ PDF ìš”ì•½ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(\"PDF íŒŒì¼ ì—…ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "    # Colabì˜ íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    # ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
    "    if not uploaded:\n",
    "        print(\"íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ì—…ë¡œë“œëœ ì²« ë²ˆì§¸ íŒŒì¼ì˜ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    pdf_filename = next(iter(uploaded))\n",
    "    print(f\"\\n'{pdf_filename}' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ìš”ì•½ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    try:\n",
    "        with open(pdf_filename, \"rb\") as f:\n",
    "            pdf_reader = PdfReader(f)\n",
    "            text_content = \"\".join(page.extract_text() for page in pdf_reader.pages)\n",
    "\n",
    "        if not text_content.strip():\n",
    "            print(\n",
    "                \"ê²½ê³ : PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¡œ ëœ PDFì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        vectorstore = process_text_to_vectorstore(text_content)\n",
    "\n",
    "        if vectorstore:\n",
    "            summarization_query = (\n",
    "                \"ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\n",
    "            )\n",
    "            summary = summarize_with_langchain(vectorstore, summarization_query)\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(\"ğŸ“œ ìš”ì•½ ê²°ê³¼\")\n",
    "            print(\"=\" * 50)\n",
    "            print(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf44681536c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_in_colab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
