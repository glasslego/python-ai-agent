"""
LLM ì¸í„°í˜ì´ìŠ¤ ëª¨ë“ˆ - ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ì ì ˆí•œ ë¶„ì„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
"""

import re
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional

from loguru import logger


@dataclass
class QueryIntent:
    """ì¿¼ë¦¬ ì˜ë„ ë¶„ì„ ê²°ê³¼"""

    intent_type: str
    confidence: float
    parameters: Dict[str, Any]
    suggested_function: str
    description: str


class LLMInterface:
    """LLM ìŠ¤íƒ€ì¼ì˜ ìì—°ì–´ ì¿¼ë¦¬ ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        """ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.intent_patterns = self._initialize_intent_patterns()
        self.function_registry = {}

    def _initialize_intent_patterns(self) -> Dict[str, Dict]:
        """ì˜ë„ ë¶„ì„ì„ ìœ„í•œ íŒ¨í„´ ì •ì˜"""
        return {
            "keyword_analysis": {
                "patterns": [
                    r"í‚¤ì›Œë“œ.*(\d+)ê°œ?",
                    r"ì¸ê¸°.*ë‹¨ì–´",
                    r"tf.?idf",
                    r"ì¤‘ìš”.*ë‹¨ì–´",
                    r"ì£¼ìš”.*í‚¤ì›Œë“œ",
                    r"ë‹¨ì–´.*ë¶„ì„",
                    r"í‚¤ì›Œë“œ.*ì¶”ì¶œ",
                ],
                "function": "analyze_keywords",
                "description": "TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ ìˆ˜í–‰",
            },
            "sentiment_analysis": {
                "patterns": [
                    r"ê°ì •.*ë¶„ì„",
                    r"ê¸ì •.*ë¶€ì •",
                    r"ê°ì„±.*ë¶„ì„",
                    r"sentiment",
                    r"ê¸°ë¶„.*ë¶„ì„",
                    r"ê°ì •.*ì ìˆ˜",
                ],
                "function": "analyze_sentiment",
                "description": "ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì • ë¶„ì„ ìˆ˜í–‰",
            },
            "clustering": {
                "patterns": [
                    r"í´ëŸ¬ìŠ¤í„°.*(\d+)ê°œ?",
                    r"ê·¸ë£¹.*(\d+)ê°œ?",
                    r"ë¶„ë¥˜.*(\d+)ê°œ?",
                    r"clustering",
                    r"ë¬¶ê¸°",
                    r"k.?means",
                ],
                "function": "perform_clustering",
                "description": "K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•œ ë‰´ìŠ¤ ë¶„ë¥˜",
            },
            "topic_modeling": {
                "patterns": [
                    r"í† í”½.*ëª¨ë¸ë§",
                    r"ì£¼ì œ.*ë¶„ì„",
                    r"topic.*model",
                    r"lda",
                    r"ì£¼ì œ.*ì¶”ì¶œ",
                    r"í† í”½.*(\d+)ê°œ?",
                ],
                "function": "model_topics",
                "description": "LDA í† í”½ ëª¨ë¸ë§ì„ í†µí•œ ì£¼ì œ ë¶„ì„",
            },
            "similarity_analysis": {
                "patterns": [
                    r"ìœ ì‚¬.*ë¬¸ì„œ",
                    r"ë¹„ìŠ·í•œ.*ê¸°ì‚¬",
                    r"ìœ ì‚¬ë„.*ë¶„ì„",
                    r"similarity",
                    r"similar.*documents",
                    r"ë¬¸ì„œ.*ìœ ì‚¬ì„±",
                ],
                "function": "analyze_similarity",
                "description": "ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ ë¶„ì„",
            },
            "data_collection": {
                "patterns": [
                    r"ë‰´ìŠ¤.*ìˆ˜ì§‘",
                    r"ë°ì´í„°.*ê°€ì ¸ì˜¤",
                    r"ê¸°ì‚¬.*(\d+)ê°œ?",
                    r"ìµœì‹ .*ë‰´ìŠ¤",
                    r"collect.*news",
                    r"fetch.*articles",
                ],
                "function": "collect_news",
                "description": "ë‰´ìŠ¤ APIë¥¼ í†µí•œ ë°ì´í„° ìˆ˜ì§‘",
            },
            "comprehensive_analysis": {
                "patterns": [
                    r"ì „ì²´.*ë¶„ì„",
                    r"ëª¨ë“ .*ë¶„ì„",
                    r"ì¢…í•©.*ë¶„ì„",
                    r"complete.*analysis",
                    r"ì „ë°˜ì .*ë¶„ì„",
                ],
                "function": "run_comprehensive_analysis",
                "description": "ëª¨ë“  ë¶„ì„ ê¸°ëŠ¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰",
            },
        }

    def register_function(self, name: str, function: Callable) -> None:
        """
        ë¶„ì„ í•¨ìˆ˜ ë“±ë¡

        Args:
            name: í•¨ìˆ˜ ì´ë¦„
            function: ì‹¤í–‰í•  í•¨ìˆ˜
        """
        self.function_registry[name] = function

    def analyze_query_intent(self, query: str) -> QueryIntent:
        """
        ìì—°ì–´ ì¿¼ë¦¬ì˜ ì˜ë„ ë¶„ì„

        Args:
            query: ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬

        Returns:
            ë¶„ì„ëœ ì˜ë„ ì •ë³´
        """
        query_lower = query.lower()
        best_match = None
        best_confidence = 0.0
        best_parameters = {}

        for intent_type, intent_config in self.intent_patterns.items():
            confidence = 0.0
            parameters = {}

            # íŒ¨í„´ ë§¤ì¹­
            for pattern in intent_config["patterns"]:
                match = re.search(pattern, query_lower)
                if match:
                    confidence += 0.3

                    # ìˆ«ì íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                    if match.groups():
                        try:
                            number = int(match.group(1))
                            if "í‚¤ì›Œë“œ" in pattern or "ë‹¨ì–´" in pattern:
                                parameters["n_keywords"] = number
                            elif (
                                "í´ëŸ¬ìŠ¤í„°" in pattern
                                or "ê·¸ë£¹" in pattern
                                or "ë¶„ë¥˜" in pattern
                            ):
                                parameters["n_clusters"] = number
                            elif "í† í”½" in pattern:
                                parameters["n_topics"] = number
                            elif "ê¸°ì‚¬" in pattern:
                                parameters["n_articles"] = number
                        except (ValueError, IndexError):
                            pass

            # í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë¢°ë„ ì¦ê°€
            keywords = {
                "keyword_analysis": ["í‚¤ì›Œë“œ", "ë‹¨ì–´", "ì¤‘ìš”", "tfidf"],
                "sentiment_analysis": ["ê°ì •", "ê¸ì •", "ë¶€ì •", "ê°ì„±"],
                "clustering": ["í´ëŸ¬ìŠ¤í„°", "ê·¸ë£¹", "ë¶„ë¥˜", "ë¬¶"],
                "topic_modeling": ["í† í”½", "ì£¼ì œ", "lda"],
                "similarity_analysis": ["ìœ ì‚¬", "ë¹„ìŠ·", "similarity"],
                "data_collection": ["ìˆ˜ì§‘", "ê°€ì ¸ì˜¤", "ìµœì‹ ", "ë‰´ìŠ¤"],
                "comprehensive_analysis": ["ì „ì²´", "ëª¨ë“ ", "ì¢…í•©", "ì „ë°˜ì "],
            }

            for keyword in keywords.get(intent_type, []):
                if keyword in query_lower:
                    confidence += 0.2

            # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
            if confidence > best_confidence:
                best_confidence = confidence
                best_match = intent_type
                best_parameters = parameters

        # ê¸°ë³¸ê°’ ì„¤ì •
        if best_match is None:
            best_match = "keyword_analysis"
            best_confidence = 0.1

        return QueryIntent(
            intent_type=best_match,
            confidence=best_confidence,
            parameters=best_parameters,
            suggested_function=self.intent_patterns[best_match]["function"],
            description=self.intent_patterns[best_match]["description"],
        )

    def process_query(self, query: str) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ ì²˜ë¦¬ ë° ë¶„ì„ ì‹¤í–‰

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬

        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        logger.info(f"\nğŸ¤– ì‚¬ìš©ì ì¿¼ë¦¬: '{query}'")

        # ì˜ë„ ë¶„ì„
        intent = self.analyze_query_intent(query)

        logger.info(f" ë¶„ì„ëœ ì˜ë„: {intent.intent_type}")
        logger.info(f"   ì‹ ë¢°ë„: {intent.confidence:.2f}")
        logger.info(f"   ì„¤ëª…: {intent.description}")
        if intent.parameters:
            logger.info(f"   íŒŒë¼ë¯¸í„°: {intent.parameters}")

        # í•¨ìˆ˜ ì‹¤í–‰
        if intent.suggested_function in self.function_registry:
            try:
                function = self.function_registry[intent.suggested_function]

                # íŒŒë¼ë¯¸í„° ì „ë‹¬í•˜ì—¬ í•¨ìˆ˜ ì‹¤í–‰
                if intent.parameters:
                    result = function(**intent.parameters)
                else:
                    result = function()

                return {
                    "success": True,
                    "intent": intent,
                    "result": result,
                    "message": f"{intent.description}ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                }

            except Exception as e:
                return {
                    "success": False,
                    "intent": intent,
                    "error": str(e),
                    "message": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                }
        else:
            return {
                "success": False,
                "intent": intent,
                "error": "Function not found",
                "message": f"'{intent.suggested_function}' í•¨ìˆ˜ê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            }

    def get_help_message(self) -> str:
        """ë„ì›€ë§ ë©”ì‹œì§€ ë°˜í™˜"""
        help_text = """
ğŸ¤– ë‰´ìŠ¤ ë¶„ì„ AI ë„ìš°ë¯¸ ì‚¬ìš©ë²•

ğŸ“ ì§€ì›í•˜ëŠ” ì¿¼ë¦¬ ì˜ˆì‹œ:

1. í‚¤ì›Œë“œ ë¶„ì„:
   â€¢ "ìµœê·¼ IT ë‰´ìŠ¤ ì¸ê¸° í‚¤ì›Œë“œ 10ê°œ"
   â€¢ "ì¤‘ìš”í•œ ë‹¨ì–´ë“¤ì„ ë¶„ì„í•´ì¤˜"
   â€¢ "TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ"

2. ê°ì • ë¶„ì„:
   â€¢ "ì‚¼ì„±ì „ì ê´€ë ¨ ë‰´ìŠ¤ ê°ì • ë¶„ì„"
   â€¢ "ê¸ì •ì ì¸ ë‰´ìŠ¤ì™€ ë¶€ì •ì ì¸ ë‰´ìŠ¤ ë¹„ìœ¨"
   â€¢ "ê°ì„± ë¶„ì„ ê²°ê³¼ ë³´ì—¬ì¤˜"

3. í´ëŸ¬ìŠ¤í„°ë§:
   â€¢ "AI ë‰´ìŠ¤ 5ê°œ ê·¸ë£¹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§"
   â€¢ "ë¹„ìŠ·í•œ ë‰´ìŠ¤ë¼ë¦¬ 3ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜"
   â€¢ "K-meansë¡œ ë‰´ìŠ¤ ë¬¶ì–´ì¤˜"

4. í† í”½ ëª¨ë¸ë§:
   â€¢ "ë‰´ìŠ¤ì˜ ì£¼ìš” í† í”½ 3ê°œ ë¶„ì„"
   â€¢ "LDA í† í”½ ëª¨ë¸ë§ ì‹¤í–‰"
   â€¢ "ì£¼ì œë³„ë¡œ ë‰´ìŠ¤ ë¶„ì„"

5. ìœ ì‚¬ë„ ë¶„ì„:
   â€¢ "ë¹„ìŠ·í•œ ë¬¸ì„œë“¤ ì°¾ì•„ì¤˜"
   â€¢ "ë¬¸ì„œ ìœ ì‚¬ë„ ë¶„ì„"
   â€¢ "ìœ ì‚¬í•œ ë‰´ìŠ¤ ê¸°ì‚¬ ê²€ìƒ‰"

6. ë°ì´í„° ìˆ˜ì§‘:
   â€¢ "ìµœì‹  IT ë‰´ìŠ¤ 50ê°œ ìˆ˜ì§‘"
   â€¢ "ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì™€ì¤˜"
   â€¢ "ê¸°ì‚¬ 100ê°œ ìˆ˜ì§‘í•´ì¤˜"

7. ì¢…í•© ë¶„ì„:
   â€¢ "ëª¨ë“  ë¶„ì„ ì‹¤í–‰í•´ì¤˜"
   â€¢ "ì „ì²´ì ì¸ ë‰´ìŠ¤ ë¶„ì„"
   â€¢ "ì¢…í•©ì ì¸ ë°ì´í„° ë¶„ì„"

ğŸ’¡ íŒ: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìš”ì²­í•˜ì‹œë©´ ë©ë‹ˆë‹¤!
        """
        return help_text

    def suggest_queries(self, category: Optional[str] = None) -> List[str]:
        """
        ì¿¼ë¦¬ ì œì•ˆ

        Args:
            category: íŠ¹ì • ì¹´í…Œê³ ë¦¬ (ì„ íƒì )

        Returns:
            ì œì•ˆ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        suggestions = {
            "keyword_analysis": [
                "ìµœê·¼ 1ì£¼ì¼ IT ë‰´ìŠ¤ ì¸ê¸° í‚¤ì›Œë“œ 10ê°œ",
                "ì¤‘ìš”í•œ ë‹¨ì–´ 20ê°œ ì¶”ì¶œí•´ì¤˜",
                "TF-IDFë¡œ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„",
            ],
            "sentiment_analysis": [
                "ì‚¼ì„±ì „ì ê´€ë ¨ ë‰´ìŠ¤ ê°ì • ë¶„ì„",
                "ì „ì²´ ë‰´ìŠ¤ì˜ ê¸ì •/ë¶€ì • ë¹„ìœ¨ ë¶„ì„",
                "ê°€ì¥ ê¸ì •ì ì¸ ë‰´ìŠ¤ì™€ ë¶€ì •ì ì¸ ë‰´ìŠ¤",
            ],
            "clustering": [
                "AI ë‰´ìŠ¤ 5ê°œ ê·¸ë£¹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§",
                "ë¹„ìŠ·í•œ ë‰´ìŠ¤ë¼ë¦¬ 3ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜",
                "ê²½ì œ ë‰´ìŠ¤ë¥¼ 4ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ë‚˜ëˆ ì¤˜",
            ],
            "topic_modeling": [
                "ë‰´ìŠ¤ì˜ ì£¼ìš” í† í”½ 5ê°œ ë¶„ì„",
                "LDAë¡œ ì£¼ì œ ëª¨ë¸ë§ ì‹¤í–‰",
                "IT ë‰´ìŠ¤ì˜ ì£¼ìš” ì£¼ì œë“¤ ì°¾ì•„ì¤˜",
            ],
            "similarity_analysis": [
                "ë¹„ìŠ·í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ ì°¾ì•„ì¤˜",
                "ë¬¸ì„œ ìœ ì‚¬ë„ ë¶„ì„ ì‹¤í–‰",
                "ì¤‘ë³µë˜ëŠ” ë‰´ìŠ¤ë“¤ ê²€ìƒ‰",
            ],
        }

        if category and category in suggestions:
            return suggestions[category]

        # ëª¨ë“  ì œì•ˆ ë°˜í™˜
        all_suggestions = []
        for category_suggestions in suggestions.values():
            all_suggestions.extend(category_suggestions)
        return all_suggestions

    def explain_intent(self, query: str) -> str:
        """
        ì¿¼ë¦¬ ì˜ë„ ì„¤ëª…

        Args:
            query: ë¶„ì„í•  ì¿¼ë¦¬

        Returns:
            ì˜ë„ ì„¤ëª… í…ìŠ¤íŠ¸
        """
        intent = self.analyze_query_intent(query)

        explanation = f"""
ğŸ” ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼

ğŸ“ ì…ë ¥ ì¿¼ë¦¬: "{query}"

ğŸ¯ ë¶„ì„ëœ ì˜ë„:
   â€¢ ìœ í˜•: {intent.intent_type}
   â€¢ ì‹ ë¢°ë„: {intent.confidence:.2f}
   â€¢ ì‹¤í–‰ í•¨ìˆ˜: {intent.suggested_function}
   â€¢ ì„¤ëª…: {intent.description}

âš™ï¸ ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°:
"""

        if intent.parameters:
            for key, value in intent.parameters.items():
                explanation += f"   â€¢ {key}: {value}\n"
        else:
            explanation += "   â€¢ íŒŒë¼ë¯¸í„° ì—†ìŒ\n"

        explanation += f"""
ğŸ’¡ ì œì•ˆ ì‚¬í•­:
   ì´ ì¿¼ë¦¬ëŠ” '{intent.description}' ê¸°ëŠ¥ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
   ì‹ ë¢°ë„ê°€ ë‚®ë‹¤ë©´ ë” êµ¬ì²´ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.
        """

        return explanation


if __name__ == "__main__":
    logger.info("ğŸ¤– LLM ì¸í„°í˜ì´ìŠ¤ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")

    # ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
    llm_interface = LLMInterface()

    # ë”ë¯¸ í•¨ìˆ˜ë“¤ ë“±ë¡
    def dummy_analyze_keywords(**kwargs):
        return f"í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰ë¨ - íŒŒë¼ë¯¸í„°: {kwargs}"

    def dummy_analyze_sentiment(**kwargs):
        return f"ê°ì • ë¶„ì„ ì‹¤í–‰ë¨ - íŒŒë¼ë¯¸í„°: {kwargs}"

    def dummy_perform_clustering(**kwargs):
        return f"í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ë¨ - íŒŒë¼ë¯¸í„°: {kwargs}"

    llm_interface.register_function("analyze_keywords", dummy_analyze_keywords)
    llm_interface.register_function("analyze_sentiment", dummy_analyze_sentiment)
    llm_interface.register_function("perform_clustering", dummy_perform_clustering)

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ìµœê·¼ IT ë‰´ìŠ¤ ì¸ê¸° í‚¤ì›Œë“œ 10ê°œ",
        "ì‚¼ì„±ì „ì ê´€ë ¨ ë‰´ìŠ¤ ê°ì • ë¶„ì„",
        "AI ë‰´ìŠ¤ 5ê°œ ê·¸ë£¹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§",
        "ì „ì²´ì ì¸ ë‰´ìŠ¤ ë¶„ì„í•´ì¤˜",
    ]

    for query in test_queries:
        logger.info(f"\n{'=' * 50}")
        result = llm_interface.process_query(query)
        logger.info(f"ê²°ê³¼: {result}")

    # ë„ì›€ë§ ì¶œë ¥
    logger.info(f"\në„ì›€ë§:\n{llm_interface.get_help_message()}")

    logger.info("\nğŸ“ ì‹¤ì œ ë¶„ì„ í•¨ìˆ˜ë“¤ê³¼ ì—°ê²°í•˜ë©´ ì™„ì „í•œ ë‰´ìŠ¤ ë¶„ì„ AIê°€ ë©ë‹ˆë‹¤.")
