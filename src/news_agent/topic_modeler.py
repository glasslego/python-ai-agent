"""
LDA í† í”½ ëª¨ë¸ë§ ëª¨ë“ˆ
"""

import warnings
from typing import Any, Dict, List, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from loguru import logger
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.feature_extraction.text import CountVectorizer

warnings.filterwarnings("ignore")

# í”Œë¡¯ ì„¤ì •
plt.rcParams["font.family"] = [
    "DejaVu Sans",
    "AppleGothic",
    "Malgun Gothic",
    "gulim",
    "Arial Unicode MS",
]
plt.rcParams["axes.unicode_minus"] = False


class TopicModeler:
    """LDA(Latent Dirichlet Allocation) í† í”½ ëª¨ë¸ë§ í´ë˜ìŠ¤"""

    def __init__(
        self,
        n_topics: int = 3,
        max_features: int = 1000,
        min_df: int = 2,
        max_df: float = 0.95,
        ngram_range: Tuple[int, int] = (1, 2),
        random_state: int = 42,
    ):
        """
        Args:
            n_topics: ì¶”ì¶œí•  í† í”½ ìˆ˜
            max_features: ìµœëŒ€ íŠ¹ì„± ìˆ˜
            min_df: ìµœì†Œ ë¬¸ì„œ ë¹ˆë„
            max_df: ìµœëŒ€ ë¬¸ì„œ ë¹ˆë„ ë¹„ìœ¨
            ngram_range: n-gram ë²”ìœ„
            random_state: ëœë¤ ì‹œë“œ
        """
        self.n_topics = n_topics
        self.random_state = random_state

        self.vectorizer = CountVectorizer(
            max_features=max_features,
            min_df=min_df,
            max_df=max_df,
            ngram_range=ngram_range,
            lowercase=False,  # ì „ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ì²˜ë¦¬
            stop_words=None,  # ì „ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ì²˜ë¦¬
        )

        self.lda = LatentDirichletAllocation(
            n_components=n_topics,
            random_state=random_state,
            max_iter=100,
            learning_method="batch",
            doc_topic_prior=None,
            topic_word_prior=None,
        )

        self.count_matrix = None
        self.doc_topic_probs = None
        self.is_fitted = False

    def fit_transform(self, texts: List[str]) -> np.ndarray:
        """
        í† í”½ ëª¨ë¸ë§ ìˆ˜í–‰

        Args:
            texts: ì…ë ¥ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë¬¸ì„œ-í† í”½ í™•ë¥  ë¶„í¬ í–‰ë ¬
        """
        if not texts:
            raise ValueError("í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°
        valid_texts = [text for text in texts if text and text.strip()]

        if not valid_texts:
            raise ValueError("ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # CountVectorizerë¡œ ë³€í™˜
        self.count_matrix = self.vectorizer.fit_transform(valid_texts)

        # LDA ëª¨ë¸ í•™ìŠµ
        self.lda.fit(self.count_matrix)

        # ë¬¸ì„œ-í† í”½ í™•ë¥  ë¶„í¬
        self.doc_topic_probs = self.lda.transform(self.count_matrix)
        self.is_fitted = True

        logger.success(f" LDA í† í”½ ëª¨ë¸ë§ ì™„ë£Œ ({self.n_topics}ê°œ í† í”½)")
        logger.info(f"   ë¬¸ì„œ ìˆ˜: {self.count_matrix.shape[0]}")
        logger.info(f"   íŠ¹ì„± ìˆ˜: {self.count_matrix.shape[1]}")
        logger.info(f"   Perplexity: {self.lda.perplexity(self.count_matrix):.2f}")

        return self.doc_topic_probs

    def get_top_words_per_topic(self, n_words: int = 10) -> List[List[str]]:
        """
        ê° í† í”½ì˜ ìƒìœ„ ë‹¨ì–´ë“¤ ì¶”ì¶œ

        Args:
            n_words: ì¶”ì¶œí•  ë‹¨ì–´ ìˆ˜

        Returns:
            í† í”½ë³„ ìƒìœ„ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
        """
        if not self.is_fitted:
            return []

        feature_names = self.vectorizer.get_feature_names_out()
        topics = []

        for topic_idx, topic in enumerate(self.lda.components_):
            top_words_idx = topic.argsort()[-n_words:][::-1]
            top_words = [feature_names[i] for i in top_words_idx]
            topics.append(top_words)

        return topics

    def get_topic_word_probabilities(
        self, topic_id: int, n_words: int = 15
    ) -> List[Tuple[str, float]]:
        """
        íŠ¹ì • í† í”½ì˜ ë‹¨ì–´ë³„ í™•ë¥  ë°˜í™˜

        Args:
            topic_id: í† í”½ ID
            n_words: ë°˜í™˜í•  ë‹¨ì–´ ìˆ˜

        Returns:
            (ë‹¨ì–´, í™•ë¥ ) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.is_fitted or topic_id >= self.n_topics:
            return []

        feature_names = self.vectorizer.get_feature_names_out()
        topic = self.lda.components_[topic_id]

        # í™•ë¥ ë¡œ ì •ê·œí™”
        topic_probs = topic / topic.sum()

        top_indices = topic_probs.argsort()[-n_words:][::-1]
        word_probs = [(feature_names[i], topic_probs[i]) for i in top_indices]

        return word_probs

    def analyze_topics(
        self, df: pd.DataFrame, show_sample_docs: int = 3, show_top_words: int = 8
    ) -> pd.DataFrame:
        """
        í† í”½ ë¶„ì„ ìˆ˜í–‰

        Args:
            df: ì›ë³¸ DataFrame
            show_sample_docs: í‘œì‹œí•  ìƒ˜í”Œ ë¬¸ì„œ ìˆ˜
            show_top_words: í‘œì‹œí•  ìƒìœ„ ë‹¨ì–´ ìˆ˜

        Returns:
            í† í”½ ì •ë³´ê°€ ì¶”ê°€ëœ DataFrame
        """
        if not self.is_fitted:
            raise ValueError("í† í”½ ëª¨ë¸ë§ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ê° ë¬¸ì„œì˜ ì£¼ìš” í† í”½ í• ë‹¹
        df_with_topics = df.copy()
        df_with_topics["main_topic"] = self.doc_topic_probs.argmax(axis=1)
        df_with_topics["topic_confidence"] = self.doc_topic_probs.max(axis=1)

        # ëª¨ë“  í† í”½ í™•ë¥  ì¶”ê°€
        for i in range(self.n_topics):
            df_with_topics[f"topic_{i}_prob"] = self.doc_topic_probs[:, i]

        logger.info("\nğŸ­ í† í”½ ëª¨ë¸ë§ ë¶„ì„ ê²°ê³¼")
        logger.info("-" * 50)

        # ê° í† í”½ì˜ ìƒìœ„ ë‹¨ì–´ë“¤
        topics = self.get_top_words_per_topic()

        self.topic_info = {}

        for i, topic_words in enumerate(topics):
            topic_docs = df_with_topics[df_with_topics["main_topic"] == i]

            logger.info(
                f"\nğŸ“š í† í”½ {i + 1} ({len(topic_docs)}ê°œ ë¬¸ì„œ, {len(topic_docs) / len(df_with_topics) * 100:.1f}%):"  # noqa: E501
            )
            logger.info(f"   ì£¼ìš” ë‹¨ì–´: {', '.join(topic_words[:show_top_words])}")

            # ìƒ˜í”Œ ë¬¸ì„œ ì œëª©ë“¤
            if len(topic_docs) > 0:
                logger.info("   ëŒ€í‘œ ë¬¸ì„œ:")
                sample_docs = topic_docs.nlargest(show_sample_docs, "topic_confidence")
                for _, doc in sample_docs.iterrows():
                    title = doc.get("Title", "ì œëª© ì—†ìŒ")[:60]
                    confidence = doc["topic_confidence"]
                    logger.info(f"     â€¢ {title}... ({confidence:.3f})")

            # í† í”½ ì •ë³´ ì €ì¥
            self.topic_info[i] = {
                "words": topic_words,
                "document_count": len(topic_docs),
                "avg_confidence": (
                    topic_docs["topic_confidence"].mean() if len(topic_docs) > 0 else 0
                ),
            }

        return df_with_topics

    def find_optimal_topics(
        self, texts: List[str], max_topics: int = 10, min_topics: int = 2
    ) -> Tuple[int, List[float]]:
        """
        ìµœì  í† í”½ ìˆ˜ ì°¾ê¸° (Perplexity ê¸°ì¤€)

        Args:
            texts: ì…ë ¥ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            max_topics: ìµœëŒ€ í† í”½ ìˆ˜
            min_topics: ìµœì†Œ í† í”½ ìˆ˜

        Returns:
            (ìµœì  í† í”½ ìˆ˜, perplexity ì ìˆ˜ ë¦¬ìŠ¤íŠ¸)
        """
        # ë°ì´í„° ìˆ˜ì— ë”°ë¼ ìµœëŒ€ í† í”½ ìˆ˜ ì¡°ì •
        n_docs = len([t for t in texts if t and t.strip()])
        max_topics = min(max_topics, n_docs // 3)

        if max_topics < min_topics:
            return min_topics, []

        logger.info(f"\nğŸ” ìµœì  í† í”½ ìˆ˜ íƒìƒ‰ ì¤‘... (ë²”ìœ„: {min_topics}-{max_topics})")

        perplexities = []
        topic_range = range(min_topics, max_topics + 1)

        for n_topics in topic_range:
            # ì„ì‹œ ëª¨ë¸ ìƒì„±
            temp_vectorizer = CountVectorizer(
                max_features=self.vectorizer.max_features,
                min_df=self.vectorizer.min_df,
                max_df=self.vectorizer.max_df,
                ngram_range=self.vectorizer.ngram_range,
            )
            temp_count_matrix = temp_vectorizer.fit_transform(texts)

            temp_lda = LatentDirichletAllocation(
                n_components=n_topics, random_state=self.random_state, max_iter=50
            )
            temp_lda.fit(temp_count_matrix)

            perplexity = temp_lda.perplexity(temp_count_matrix)
            perplexities.append(perplexity)

            logger.info(f"   í† í”½ ìˆ˜ {n_topics}: Perplexity = {perplexity:.2f}")

        # ê°€ì¥ ë‚®ì€ perplexityë¥¼ ê°€ì§„ í† í”½ ìˆ˜ ì„ íƒ
        optimal_idx = np.argmin(perplexities)
        optimal_topics = topic_range[optimal_idx]

        logger.info(
            f"\nâœ… ìµœì  í† í”½ ìˆ˜: {optimal_topics} (Perplexity: {perplexities[optimal_idx]:.2f})"  # noqa: E501
        )

        return optimal_topics, perplexities

    def visualize_topics(
        self,
        df_with_topics: pd.DataFrame,
        save_path: str = "topic_modeling_analysis.png",
    ) -> None:
        """
        í† í”½ ì‹œê°í™”

        Args:
            df_with_topics: í† í”½ ì •ë³´ê°€ í¬í•¨ëœ DataFrame
            save_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        if not self.is_fitted:
            raise ValueError("í† í”½ ëª¨ë¸ë§ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info("\nğŸ“Š í† í”½ ì‹œê°í™” ìƒì„± ì¤‘...")

        colors = [
            "#FF6B6B",
            "#4ECDC4",
            "#45B7D1",
            "#96CEB4",
            "#FFEAA7",
            "#DDA0DD",
            "#FFB347",
            "#98FB98",
        ]

        # ê·¸ë˜í”„ ì„¤ì •
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # 1. í† í”½ë³„ ë¬¸ì„œ ë¶„í¬ (ì›í˜•ì°¨íŠ¸)
        topic_counts = df_with_topics["main_topic"].value_counts().sort_index()
        axes[0, 0].pie(
            topic_counts.values,
            labels=[f"Topic {i + 1}" for i in topic_counts.index],
            autopct="%1.1f%%",
            colors=colors[: len(topic_counts)],
            startangle=90,
        )
        axes[0, 0].set_title(
            "Document Distribution by Topic", fontsize=14, fontweight="bold"
        )

        # 2. í† í”½ë³„ ì‹ ë¢°ë„ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)
        for topic_id in range(self.n_topics):
            topic_data = df_with_topics[df_with_topics["main_topic"] == topic_id]
            if len(topic_data) > 0:
                axes[0, 1].hist(
                    topic_data["topic_confidence"],
                    alpha=0.7,
                    label=f"Topic {topic_id + 1}",
                    color=colors[topic_id % len(colors)],
                    bins=15,
                )

        axes[0, 1].set_title(
            "Topic Confidence Distribution", fontsize=14, fontweight="bold"
        )
        axes[0, 1].set_xlabel("Confidence Score")
        axes[0, 1].set_ylabel("Frequency")
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # 3. í† í”½-ë‹¨ì–´ íˆíŠ¸ë§µ
        feature_names = self.vectorizer.get_feature_names_out()

        # ìƒìœ„ ë‹¨ì–´ë“¤ ì„ íƒ
        all_top_words = set()
        for topic_idx in range(self.n_topics):
            topic_words = self.get_top_words_per_topic(8)[topic_idx]
            all_top_words.update(topic_words[:5])

        top_words = list(all_top_words)[:12]  # ìµœëŒ€ 12ê°œ ë‹¨ì–´

        # íˆíŠ¸ë§µ ë°ì´í„° ìƒì„±
        heatmap_data = []
        for topic_idx in range(self.n_topics):
            topic = self.lda.components_[topic_idx]
            topic_normalized = topic / topic.sum()  # ì •ê·œí™”

            topic_scores = []
            for word in top_words:
                if word in feature_names:
                    word_idx = list(feature_names).index(word)
                    topic_scores.append(topic_normalized[word_idx])
                else:
                    topic_scores.append(0)
            heatmap_data.append(topic_scores)

        im = axes[1, 0].imshow(heatmap_data, cmap="YlOrRd", aspect="auto")
        axes[1, 0].set_xticks(range(len(top_words)))
        axes[1, 0].set_xticklabels(top_words, rotation=45, ha="right")
        axes[1, 0].set_yticks(range(self.n_topics))
        axes[1, 0].set_yticklabels([f"Topic {i + 1}" for i in range(self.n_topics)])
        axes[1, 0].set_title(
            "Topic-Word Intensity Heatmap", fontsize=14, fontweight="bold"
        )

        # ì»¬ëŸ¬ë°” ì¶”ê°€
        plt.colorbar(im, ax=axes[1, 0], shrink=0.8)

        # 4. í† í”½ë³„ í‰ê·  ì‹ ë¢°ë„
        avg_confidence = df_with_topics.groupby("main_topic")["topic_confidence"].mean()
        bars = axes[1, 1].bar(
            range(self.n_topics),
            avg_confidence.values,
            color=colors[: self.n_topics],
            alpha=0.8,
        )
        axes[1, 1].set_title("Average Topic Confidence", fontsize=14, fontweight="bold")
        axes[1, 1].set_xlabel("Topic")
        axes[1, 1].set_ylabel("Average Confidence")
        axes[1, 1].set_xticks(range(self.n_topics))
        axes[1, 1].set_xticklabels([f"Topic {i + 1}" for i in range(self.n_topics)])
        axes[1, 1].grid(True, alpha=0.3)

        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar, value in zip(bars, avg_confidence.values):
            axes[1, 1].text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() + 0.01,
                f"{value:.3f}",
                ha="center",
                va="bottom",
            )

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.show()

        logger.info(f"   ğŸ“ ì‹œê°í™” ê²°ê³¼ê°€ '{save_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def export_results(
        self, df_with_topics: pd.DataFrame, output_prefix: str = "topic_modeling"
    ) -> Dict[str, str]:
        """
        í† í”½ ëª¨ë¸ë§ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°

        Args:
            df_with_topics: í† í”½ ì •ë³´ê°€ í¬í•¨ëœ DataFrame
            output_prefix: ì¶œë ¥ íŒŒì¼ ì ‘ë‘ì‚¬

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        if not self.is_fitted:
            raise ValueError("í† í”½ ëª¨ë¸ë§ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        saved_files = {}

        logger.info("\nğŸ’¾ í† í”½ ëª¨ë¸ë§ ê²°ê³¼ ì €ì¥ ì¤‘...")

        # 1. ë¬¸ì„œë³„ í† í”½ ê²°ê³¼ ì €ì¥
        results_file = f"{output_prefix}_results.csv"
        df_with_topics.to_csv(results_file, index=False, encoding="utf-8-sig")
        saved_files["results"] = results_file

        # 2. í† í”½ë³„ ìƒìœ„ ë‹¨ì–´ ì €ì¥
        topics = self.get_top_words_per_topic(15)
        topic_words_data = []

        for i, topic_words in enumerate(topics):
            topic_words_data.append(
                {
                    "topic_id": i + 1,
                    "top_words": ", ".join(topic_words),
                    "word_list": topic_words,
                }
            )

        topic_df = pd.DataFrame(topic_words_data)
        words_file = f"{output_prefix}_words.csv"
        topic_df.to_csv(words_file, index=False, encoding="utf-8-sig")
        saved_files["words"] = words_file

        # 3. í† í”½ë³„ ìš”ì•½ í†µê³„ ì €ì¥
        summary_data = []
        for topic_id in range(self.n_topics):
            topic_docs = df_with_topics[df_with_topics["main_topic"] == topic_id]

            summary = {
                "topic_id": topic_id + 1,
                "document_count": len(topic_docs),
                "percentage": len(topic_docs) / len(df_with_topics) * 100,
                "avg_confidence": (
                    topic_docs["topic_confidence"].mean() if len(topic_docs) > 0 else 0
                ),
                "sample_titles": (
                    topic_docs["Title"].head(3).tolist() if len(topic_docs) > 0 else []
                ),
                "top_words": ", ".join(topics[topic_id][:5]),
            }
            summary_data.append(summary)

        summary_file = f"{output_prefix}_summary.csv"
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(summary_file, index=False, encoding="utf-8-sig")
        saved_files["summary"] = summary_file

        # 4. ë¬¸ì„œ-í† í”½ í™•ë¥  í–‰ë ¬ ì €ì¥
        prob_df = pd.DataFrame(
            self.doc_topic_probs,
            columns=[f"Topic_{i + 1}_Prob" for i in range(self.n_topics)],
        )
        prob_df["Title"] = df_with_topics["Title"].reset_index(drop=True)
        prob_file = f"{output_prefix}_probabilities.csv"
        prob_df.to_csv(prob_file, index=False, encoding="utf-8-sig")
        saved_files["probabilities"] = prob_file

        logger.info(f"   ğŸ“„ í† í”½ ê²°ê³¼: {results_file}")
        logger.info(f"   ğŸ”¤ í† í”½ ë‹¨ì–´: {words_file}")
        logger.info(f"   ğŸ“Š í† í”½ ìš”ì•½: {summary_file}")
        logger.info(f"   ğŸ“ˆ í™•ë¥  í–‰ë ¬: {prob_file}")

        return saved_files

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        if not self.is_fitted:
            return {}

        return {
            "n_topics": self.n_topics,
            "n_documents": (
                self.count_matrix.shape[0] if self.count_matrix is not None else 0
            ),
            "n_features": (
                self.count_matrix.shape[1] if self.count_matrix is not None else 0
            ),
            "perplexity": (
                self.lda.perplexity(self.count_matrix)
                if self.count_matrix is not None
                else 0
            ),
            "log_likelihood": (
                self.lda.score(self.count_matrix)
                if self.count_matrix is not None
                else 0
            ),
        }


if __name__ == "__main__":
    logger.info("ğŸ­ í† í”½ ëª¨ë¸ë§ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")

    df = pd.read_csv("processed_news.csv")
    sample_texts = df["processed_text"].dropna().tolist()

    # í† í”½ ëª¨ë¸ë§ ìˆ˜í–‰
    modeler = TopicModeler(n_topics=3, max_features=50)
    doc_topic_probs = modeler.fit_transform(sample_texts)

    # ë¶„ì„ ê²°ê³¼
    df_with_topics = modeler.analyze_topics(df)

    # ëª¨ë¸ ì •ë³´
    info = modeler.get_model_info()
    logger.info(f"\nëª¨ë¸ ì •ë³´: {info}")
