"""
NLTK VADER ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë“ˆ
"""

import ssl
import warnings
from typing import Any, Dict, List, Optional

import matplotlib.pyplot as plt
import nltk
import pandas as pd
import seaborn as sns
from loguru import logger
from nltk.sentiment import SentimentIntensityAnalyzer

# í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = "AppleGothic"  # MacOS

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings(
    "ignore", category=UserWarning, module="matplotlib.font_manager"
)

# SSL ì¸ì¦ì„œ ë¬¸ì œ í•´ê²°
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context


class SentimentAnalyzer:
    """NLTK VADER ê¸°ë°˜ ê°ì • ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, download_vader: bool = True):
        """
        Args:
            download_vader: VADER ì‚¬ì „ ìë™ ë‹¤ìš´ë¡œë“œ ì—¬ë¶€
        """
        if download_vader:
            try:
                nltk.download("vader_lexicon", quiet=True)
            except Exception as e:
                logger.info(f"VADER ë‹¤ìš´ë¡œë“œ ì¤‘ ì—ëŸ¬: {e}")

        self.sia = SentimentIntensityAnalyzer()
        self.sentiment_threshold = {"positive": 0.05, "negative": -0.05}

    def analyze_single_text(self, text: str) -> Dict[str, Any]:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸

        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not isinstance(text, str) or not text.strip():
            return {
                "sentiment": "neutral",
                "positive": 0.0,
                "negative": 0.0,
                "neutral": 1.0,
                "compound": 0.0,
                "confidence": 0.0,
            }

        scores = self.sia.polarity_scores(text)

        # ê°ì • ë¶„ë¥˜
        compound = scores["compound"]
        if compound >= self.sentiment_threshold["positive"]:
            sentiment = "positive"
            confidence = abs(compound)
        elif compound <= self.sentiment_threshold["negative"]:
            sentiment = "negative"
            confidence = abs(compound)
        else:
            sentiment = "neutral"
            confidence = 1 - abs(compound)  # ì¤‘ì„±ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„

        return {
            "sentiment": sentiment,
            "positive": scores["pos"],
            "negative": scores["neg"],
            "neutral": scores["neu"],
            "compound": compound,
            "confidence": confidence,
        }

    def analyze_dataframe(
        self, df: pd.DataFrame, text_columns: Optional[List[str]] = None
    ) -> pd.DataFrame:
        """
        DataFrame ì „ì²´ ê°ì • ë¶„ì„

        Args:
            df: ë¶„ì„í•  DataFrame
            text_columns: ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
                         (Noneì¸ ê²½ìš° ê¸°ë³¸ ì»¬ëŸ¼ë“¤ ì‚¬ìš©)

        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ DataFrame
        """
        if df.empty:
            return df

        df_copy = df.copy()

        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„¤ì •
        if text_columns is None:
            text_columns = [
                "Title",
                "Description",
                "Parsed Content",
                "Content",
                "processed_text",
            ]

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì°¾ê¸°
        available_columns = [col for col in text_columns if col in df_copy.columns]

        if not available_columns:
            logger.error(" ë¶„ì„í•  í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return df_copy

        logger.info("\nğŸ˜Š ê°ì • ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        logger.info(f"   ğŸ“ ë¶„ì„ ì»¬ëŸ¼: {', '.join(available_columns)}")
        logger.info("-" * 50)

        # ê° ê¸°ì‚¬ì˜ ê°ì • ë¶„ì„
        sentiment_results = []

        for idx, row in df_copy.iterrows():
            # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ê²°í•©
            combined_text = ""
            for col in available_columns:
                if pd.notna(row[col]):
                    combined_text += f" {str(row[col])}"

            combined_text = combined_text.strip()
            result = self.analyze_single_text(combined_text)
            sentiment_results.append(result)

            # ì§„í–‰ ìƒí™© í‘œì‹œ
            if (idx + 1) % 10 == 0 or idx == len(df_copy) - 1:
                logger.info(
                    f"   ğŸ“Š ì§„í–‰ë¥ : {idx + 1}/{len(df_copy)} ({(idx + 1) / len(df_copy) * 100:.1f}%)"  # noqa: E501
                )

        # ê²°ê³¼ë¥¼ DataFrameì— ì¶”ê°€
        sentiment_df = pd.DataFrame(sentiment_results)
        df_result = pd.concat([df_copy, sentiment_df], axis=1)

        # ê°ì • ë¶„í¬ ì¶œë ¥
        self._print_sentiment_analysis_summary(df_result)

        return df_result

    def _print_sentiment_analysis_summary(self, df_result: pd.DataFrame) -> None:
        """ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        sentiment_counts = df_result["sentiment"].value_counts()
        total_docs = len(df_result)

        logger.info("\nğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 40)
        logger.info(f"ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: {total_docs}ê°œ")
        logger.info("-" * 40)

        # ê° ê°ì •ë³„ ìƒì„¸ ì •ë³´
        emoji_map = {"positive": "ğŸ˜Š", "negative": "ğŸ˜", "neutral": "ğŸ˜"}

        for sentiment in ["positive", "negative", "neutral"]:
            count = sentiment_counts.get(sentiment, 0)
            percentage = (count / total_docs) * 100

            logger.info(
                f"{emoji_map[sentiment]} {sentiment.capitalize()}: {count}ê°œ ({percentage:.1f}%)"  # noqa: E501
            )

            # í•´ë‹¹ ê°ì •ì˜ í†µê³„
            if count > 0:
                sentiment_data = df_result[df_result["sentiment"] == sentiment]
                avg_compound = sentiment_data["compound"].mean()
                avg_confidence = sentiment_data["confidence"].mean()
                logger.info(f"   â†³ í‰ê·  ì ìˆ˜: {avg_compound:.3f}")
                logger.info(f"   â†³ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")

        logger.info("-" * 40)

        # ì „ì²´ í†µê³„
        avg_compound = df_result["compound"].mean()
        logger.info(f" ì „ì²´ í‰ê·  ê°ì • ì ìˆ˜: {avg_compound:.3f}")

        # ê°ì • ì„±í–¥ ë¶„ì„
        positive_ratio = sentiment_counts.get("positive", 0) / total_docs
        negative_ratio = sentiment_counts.get("negative", 0) / total_docs

        if positive_ratio > negative_ratio * 1.5:
            trend = "ğŸ“ˆ ì „ë°˜ì ìœ¼ë¡œ ê¸ì •ì  ì„±í–¥"
        elif negative_ratio > positive_ratio * 1.5:
            trend = "ğŸ“‰ ì „ë°˜ì ìœ¼ë¡œ ë¶€ì •ì  ì„±í–¥"
        else:
            trend = "âš–ï¸  ê· í˜•ì¡íŒ ê°ì • ë¶„í¬"

        logger.info(f" ê°ì • ì„±í–¥: {trend}")

    def get_sentiment_statistics(self, df_result: pd.DataFrame) -> Dict[str, Any]:
        """
        ìƒì„¸í•œ ê°ì • í†µê³„ ë°˜í™˜

        Args:
            df_result: ê°ì • ë¶„ì„ëœ DataFrame

        Returns:
            ê°ì • í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        if "sentiment" not in df_result.columns:
            return {}

        stats = {
            "total_documents": len(df_result),
            "sentiment_distribution": {},
            "compound_stats": {
                "mean": float(df_result["compound"].mean()),
                "std": float(df_result["compound"].std()),
                "min": float(df_result["compound"].min()),
                "max": float(df_result["compound"].max()),
            },
        }

        # ê°ì •ë³„ í†µê³„
        for sentiment in ["positive", "negative", "neutral"]:
            sentiment_data = df_result[df_result["sentiment"] == sentiment]

            stats["sentiment_distribution"][sentiment] = {
                "count": len(sentiment_data),
                "percentage": len(sentiment_data) / len(df_result) * 100,
                "avg_compound": (
                    float(sentiment_data["compound"].mean())
                    if len(sentiment_data) > 0
                    else 0
                ),
                "avg_confidence": (
                    float(sentiment_data["confidence"].mean())
                    if len(sentiment_data) > 0
                    else 0
                ),
                "std_compound": (
                    float(sentiment_data["compound"].std())
                    if len(sentiment_data) > 0
                    else 0
                ),
            }

        return stats

    def get_extreme_sentiments(
        self, df_result: pd.DataFrame, n_samples: int = 3
    ) -> Dict[str, List[Dict]]:
        """
        ê·¹ë‹¨ì  ê°ì • ê¸°ì‚¬ ì¶”ì¶œ

        Args:
            df_result: ê°ì • ë¶„ì„ëœ DataFrame
            n_samples: ì¶”ì¶œí•  ìƒ˜í”Œ ìˆ˜

        Returns:
            ê·¹ë‹¨ì  ê°ì • ê¸°ì‚¬ ë”•ì…”ë„ˆë¦¬
        """
        if "compound" not in df_result.columns:
            return {}

        # ê°€ì¥ ê¸ì •ì ì¸ ê¸°ì‚¬ë“¤
        most_positive = df_result.nlargest(n_samples, "compound")
        positive_samples = []
        for _, row in most_positive.iterrows():
            positive_samples.append(
                {
                    "title": row.get("Title", "ì œëª© ì—†ìŒ"),
                    "compound": row["compound"],
                    "confidence": row.get("confidence", 0),
                }
            )

        # ê°€ì¥ ë¶€ì •ì ì¸ ê¸°ì‚¬ë“¤
        most_negative = df_result.nsmallest(n_samples, "compound")
        negative_samples = []
        for _, row in most_negative.iterrows():
            negative_samples.append(
                {
                    "title": row.get("Title", "ì œëª© ì—†ìŒ"),
                    "compound": row["compound"],
                    "confidence": row.get("confidence", 0),
                }
            )

        return {"most_positive": positive_samples, "most_negative": negative_samples}

    def visualize_sentiments(
        self, df_result: pd.DataFrame, save_path: str = "sentiment_analysis_results.png"
    ) -> None:
        """
        ê°ì • ë¶„ì„ ê²°ê³¼ ì‹œê°í™”

        Args:
            df_result: ê°ì • ë¶„ì„ëœ DataFrame
            save_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        """
        if "sentiment" not in df_result.columns:
            logger.error(" ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        logger.info("\nğŸ“Š ê°ì • ë¶„ì„ ì‹œê°í™” ìƒì„± ì¤‘...")

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle("ë‰´ìŠ¤ ê¸°ì‚¬ ê°ì • ë¶„ì„ ê²°ê³¼", fontsize=16, fontweight="bold")

        # 1. ê°ì • ë¶„í¬ íŒŒì´ ì°¨íŠ¸
        sentiment_counts = df_result["sentiment"].value_counts()
        colors = ["#2ecc71", "#e74c3c", "#95a5a6"]  # green, red, gray

        axes[0, 0].pie(
            sentiment_counts.values,
            labels=[
                f"{label.capitalize()}\n({count}ê°œ)"
                for label, count in sentiment_counts.items()
            ],
            autopct="%1.1f%%",
            colors=colors[: len(sentiment_counts)],
            startangle=90,
        )
        axes[0, 0].set_title("ê°ì • ë¶„í¬", fontsize=14)

        # 2. Compound ì ìˆ˜ íˆìŠ¤í† ê·¸ë¨
        axes[0, 1].hist(
            df_result["compound"],
            bins=25,
            color="skyblue",
            alpha=0.7,
            edgecolor="black",
        )
        axes[0, 1].axvline(x=0, color="red", linestyle="--", alpha=0.7, label="ì¤‘ì„±ì„ ")
        axes[0, 1].axvline(
            x=self.sentiment_threshold["positive"],
            color="green",
            linestyle=":",
            alpha=0.7,
            label="ê¸ì • ì„ê³„ê°’",
        )
        axes[0, 1].axvline(
            x=self.sentiment_threshold["negative"],
            color="red",
            linestyle=":",
            alpha=0.7,
            label="ë¶€ì • ì„ê³„ê°’",
        )
        axes[0, 1].set_title("Compound ì ìˆ˜ ë¶„í¬", fontsize=14)
        axes[0, 1].set_xlabel("Compound Score")
        axes[0, 1].set_ylabel("ê¸°ì‚¬ ìˆ˜")
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # 3. ê°ì •ë³„ Compound ì ìˆ˜ ë°•ìŠ¤í”Œë¡¯
        sentiment_order = ["negative", "neutral", "positive"]
        available_sentiments = [
            s for s in sentiment_order if s in sentiment_counts.index
        ]

        if available_sentiments:
            sns.boxplot(
                data=df_result,
                x="sentiment",
                y="compound",
                order=available_sentiments,
                ax=axes[1, 0],
            )
        axes[1, 0].set_title("ê°ì •ë³„ Compound ì ìˆ˜ ë¶„í¬", fontsize=14)
        axes[1, 0].set_xlabel("ê°ì •")
        axes[1, 0].set_ylabel("Compound Score")
        axes[1, 0].grid(True, alpha=0.3)

        # 4. ê°ì • ì ìˆ˜ ìƒê´€ê´€ê³„
        score_columns = ["positive", "negative", "neutral", "compound"]
        available_score_columns = [
            col for col in score_columns if col in df_result.columns
        ]

        if len(available_score_columns) > 1:
            corr_data = df_result[available_score_columns].corr()
            sns.heatmap(
                corr_data,
                annot=True,
                cmap="RdBu_r",
                center=0,
                ax=axes[1, 1],
                square=True,
            )
        axes[1, 1].set_title("ê°ì • ì ìˆ˜ ìƒê´€ê´€ê³„", fontsize=14)

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.show()

        logger.info(f"   ğŸ“ ì‹œê°í™” ê²°ê³¼ê°€ '{save_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def export_results(
        self, df_result: pd.DataFrame, output_prefix: str = "sentiment_analysis"
    ) -> Dict[str, str]:
        """
        ê°ì • ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°

        Args:
            df_result: ê°ì • ë¶„ì„ëœ DataFrame
            output_prefix: ì¶œë ¥ íŒŒì¼ ì ‘ë‘ì‚¬

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        saved_files = {}

        logger.info("\nğŸ’¾ ê°ì • ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")

        # 1. ì „ì²´ ê²°ê³¼ ì €ì¥
        results_file = f"{output_prefix}_results.csv"
        df_result.to_csv(results_file, index=False, encoding="utf-8-sig")
        saved_files["results"] = results_file

        # 2. ìš”ì•½ í†µê³„ ì €ì¥
        stats = self.get_sentiment_statistics(df_result)
        summary_file = f"{output_prefix}_summary.csv"

        summary_data = []
        summary_data.append(
            {"metric": "total_documents", "value": stats["total_documents"]}
        )

        for sentiment, data in stats["sentiment_distribution"].items():
            summary_data.extend(
                [
                    {"metric": f"{sentiment}_count", "value": data["count"]},
                    {"metric": f"{sentiment}_percentage", "value": data["percentage"]},
                    {
                        "metric": f"{sentiment}_avg_compound",
                        "value": data["avg_compound"],
                    },
                    {
                        "metric": f"{sentiment}_avg_confidence",
                        "value": data["avg_confidence"],
                    },
                ]
            )

        for metric, value in stats["compound_stats"].items():
            summary_data.append({"metric": f"compound_{metric}", "value": value})

        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(summary_file, index=False, encoding="utf-8-sig")
        saved_files["summary"] = summary_file

        # 3. ê·¹ë‹¨ì  ê°ì • ê¸°ì‚¬ ì €ì¥
        extremes = self.get_extreme_sentiments(df_result, 5)
        if extremes:
            extreme_data = []

            for pos_sample in extremes["most_positive"]:
                extreme_data.append(
                    {
                        "type": "most_positive",
                        "title": pos_sample["title"],
                        "compound": pos_sample["compound"],
                        "confidence": pos_sample["confidence"],
                    }
                )

            for neg_sample in extremes["most_negative"]:
                extreme_data.append(
                    {
                        "type": "most_negative",
                        "title": neg_sample["title"],
                        "compound": neg_sample["compound"],
                        "confidence": neg_sample["confidence"],
                    }
                )

            extreme_file = f"{output_prefix}_extremes.csv"
            extreme_df = pd.DataFrame(extreme_data)
            extreme_df.to_csv(extreme_file, index=False, encoding="utf-8-sig")
            saved_files["extremes"] = extreme_file

        logger.info(f"   ğŸ“„ ì „ì²´ ê²°ê³¼: {results_file}")
        logger.info(f"   ğŸ“Š ìš”ì•½ í†µê³„: {summary_file}")
        if "extremes" in saved_files:
            logger.info(f"   ğŸ¯ ê·¹ë‹¨ì  ê°ì •: {saved_files['extremes']}")

        return saved_files


if __name__ == "__main__":
    logger.info("ğŸ˜Š ê°ì • ë¶„ì„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")

    df = pd.read_csv("../processed_news.csv")

    # ê°ì • ë¶„ì„ ìˆ˜í–‰
    analyzer = SentimentAnalyzer()
    df_result = analyzer.analyze_dataframe(df, text_columns=["Title", "processed_text"])

    # í†µê³„ ì¶œë ¥
    stats = analyzer.get_sentiment_statistics(df_result)
    logger.info(f"\nê°ì • í†µê³„: {stats}")

    # ê·¹ë‹¨ì  ê°ì • ê¸°ì‚¬
    extremes = analyzer.get_extreme_sentiments(df_result, 2)
    logger.info(f"\nê·¹ë‹¨ì  ê°ì •: {extremes}")
